{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = green>Gesture Recognition -DS C27 batch<font> \n",
    "\n",
    "##### <font color = green> By:<font> \n",
    "<font color = red>    **1. MOHAMMAD SHAHID RASHID**<font>     <font color = blue>     (mohammad.shahid.rashid@gmail.com) <font> <br> \n",
    "<font color = red>    **2. DHARMENDRA BUDHA**<font><font>  <font color = blue>   (dharmendra.budha@gmail.com) <font>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = blue>**Project Overview:**</font>\n",
    "\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started.\n",
    "\n",
    "Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.\n",
    "\n",
    "The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a **sequence of 30 frames(images)**. These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use. \n",
    " \n",
    "Homogenous data will not be there. It will come from various source of different sizes like 360 * 360 and 120 * 160 pixels. So to utilize them we have to make them uniform in size.\n",
    "\n",
    "\n",
    "## <font color = blue>**Goals of this Project:**</font>\n",
    "\n",
    "Build a model to recognise 5 hand gestures. The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
    "\n",
    "\t• Thumbs up:  Increase the volume\n",
    "\t• Thumbs down: Decrease the volume\n",
    "\t• Left swipe: 'Jump' backwards 10 seconds\n",
    "\t• Right swipe: 'Jump' forward 10 seconds  \n",
    "\t• Stop: Pause the movie\n",
    "\n",
    "\n",
    "We need to accomplish the following in the project:\n",
    "\n",
    "   1. **Generator**:  The generator should be able to take a batch of videos as input without any error. Steps like **cropping, resizing and normalization** should be performed successfully.\n",
    "   2. **Model**: Develop a model that is able to train without any errors which will be judged on the total number of parameters (as the inference(prediction) time should be less) and the accuracy achieved.\n",
    "   3. **Write up**: This should contain the detailed procedure followed in choosing the final model. The write up should start with the reason for choosing the base model, then highlight the reasons and metrics taken into consideration to modify and experiment to arrive at the final model.\n",
    "   \n",
    "   \n",
    "In this project, we are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Import libraries to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`import all required Python libaries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, ZeroPadding3D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.random.set_seed(30)\n",
    "\n",
    "train_path = './Project_data/train'\n",
    "val_path = './Project_data/val'\n",
    "train_doc = np.random.permutation(open('./Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('./Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator  Class\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, we are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. We have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, width=120, height=120, frames=30, channel=3, \n",
    "                 crop = True, normalize = False, affine = False, flip = False, edge = False  ):\n",
    "        self.width = width   # X dimension of the image\n",
    "        self.height = height # Y dimesnion of the image\n",
    "        self.frames = frames # length/depth of the video frames\n",
    "        self.channel = channel # number of channels in images 3 for color(RGB) and 1 for Gray  \n",
    "        self.affine = affine # augment data with affine transform of the image\n",
    "        self.flip = flip\n",
    "        self.normalize =  normalize\n",
    "        self.edge = edge # edge detection\n",
    "        self.crop = crop\n",
    "\n",
    "    # Helper function to generate a random affine transform on the image\n",
    "    def __get_random_affine(self): # private method\n",
    "        dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        return M\n",
    "\n",
    "    # Helper function to initialize all the batch image data and labels\n",
    "    def __init_batch_data(self, batch_size): # private method\n",
    "        batch_data = np.zeros((batch_size, self.frames, self.width, self.height, self.channel)) \n",
    "        batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    def __load_batch_images(self, source_path, folder_list, batch_num, batch_size, t): # private method\n",
    "    \n",
    "        batch_data,batch_labels = self.__init_batch_data(batch_size)\n",
    "        # We will also build a agumented batch data\n",
    "        if self.affine:\n",
    "            batch_data_aug,batch_labels_aug = self.__init_batch_data(batch_size)\n",
    "        if self.flip:\n",
    "            batch_data_flip,batch_labels_flip = self.__init_batch_data(batch_size)\n",
    "\n",
    "        #create a list of image numbers you want to use for a particular video\n",
    "        img_idx = [x for x in range(0, self.frames)] \n",
    "\n",
    "        for folder in range(batch_size): # iterate over the batch_size\n",
    "            # read all the images in the folder\n",
    "            imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "            # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "            M = self.__get_random_affine()\n",
    "            \n",
    "            #  Iterate over the frames/images of a folder to read them in\n",
    "            for idx, item in enumerate(img_idx): \n",
    "                image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                #and the conv3D will throw error if the inputs in a batch have different shapes  \n",
    "                if self.crop:\n",
    "                    image = self.__crop(image)\n",
    "                # If normalize is set normalize the image else use the raw image.\n",
    "                if self.normalize:\n",
    "                    resized = self.__normalize(self.__resize(image))\n",
    "                else:\n",
    "                    resized = self.__resize(image)\n",
    "                # If the input is edge detected image then use the sobelx, sobely and laplacian as 3 channel of the edge detected image\n",
    "                if self.edge:\n",
    "                    resized = self.__edge(resized)\n",
    "                \n",
    "                batch_data[folder,idx] = resized\n",
    "                if self.affine:\n",
    "                    batch_data_aug[folder,idx] = self.__affine(resized, M)   \n",
    "                if self.flip:\n",
    "                    batch_data_flip[folder,idx] = self.__flip(resized)   \n",
    "\n",
    "            batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "            if self.affine:\n",
    "                batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "            if self.flip:\n",
    "                if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "                elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        if self.affine:\n",
    "            batch_data = np.append(batch_data, batch_data_aug, axis = 0) \n",
    "            batch_labels = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "        if self.flip:\n",
    "            batch_data = np.append(batch_data, batch_data_flip, axis = 0) \n",
    "            batch_labels = np.append(batch_labels, batch_labels_flip, axis = 0) \n",
    "\n",
    "        return batch_data, batch_labels\n",
    "    \n",
    "    def generator(self, source_path, folder_list, batch_size): # public method\n",
    "        print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "                yield self.__load_batch_images(source_path, folder_list, batch, batch_size, t) \n",
    "            \n",
    "            # Code for the remaining data points which are left after full batches\n",
    "            if (len(folder_list) != batch_size*num_batches):\n",
    "                batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "                yield self.__load_batch_images(source_path, folder_list, num_batches, batch_size, t)\n",
    "\n",
    "    # Helper function to perfom affice transform on the image\n",
    "    def __affine(self, image, M):\n",
    "        return cv2.warpAffine(image, M, (image.shape[0], image.shape[1]))\n",
    "\n",
    "    # Helper function to flip the image\n",
    "    def __flip(self, image):\n",
    "        return np.flip(image,1)\n",
    "    \n",
    "    # Helper function to normalise the data\n",
    "    def __normalize(self, image):\n",
    "        return image/127.5-1\n",
    "    \n",
    "    # Helper function to resize the image\n",
    "    def __resize(self, image):\n",
    "        return cv2.resize(image, (self.width,self.height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Helper function to crop the image\n",
    "    def __crop(self, image):\n",
    "        if image.shape[0] != image.shape[1]:\n",
    "            return image[0:120, 20:140]\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    # Helper function for edge detection\n",
    "    def __edge(self, image):\n",
    "        edge = np.zeros((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        edge[:,:,0] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,0],(3,3),0),cv2.CV_64F)\n",
    "        edge[:,:,1] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,1],(3,3),0),cv2.CV_64F)\n",
    "        edge[:,:,2] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,2],(3,3),0),cv2.CV_64F)\n",
    "        return edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here we make the model using different functionalities that Keras provides. We use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model.Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGenerator(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d1(cls, input_shape, nb_classes):\n",
    "        \"\"\"\n",
    "        Build a 3D convolutional network, based loosely on C3D.\n",
    "            https://arxiv.org/pdf/1412.0767.pdf\n",
    "        \"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(\n",
    "            8, (3,3,3), activation='relu', input_shape=input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(16, (3,3,3), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(32, (3,3,3), activation='relu'))\n",
    "        model.add(Conv3D(32, (3,3,3), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(64, (2,2,2), activation='relu'))\n",
    "        model.add(Conv3D(64, (2,2,2), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(256))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d2(cls, input_shape, nb_classes):\n",
    "        \"\"\"\n",
    "        Build a 3D convolutional network, aka C3D.\n",
    "            https://arxiv.org/pdf/1412.0767.pdf\n",
    "        \"\"\"        \n",
    "        model = Sequential()\n",
    "        # 1st layer group\n",
    "        model.add(Conv3D(16, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv1',\n",
    "                         subsample=(1, 1, 1),\n",
    "                         input_shape=input_shape))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                               border_mode='valid', name='pool1'))\n",
    "        # 2nd layer group\n",
    "        model.add(Conv3D(32, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv2',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool2'))\n",
    "        # 3rd layer group\n",
    "        model.add(Conv3D(64, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv3a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(64, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv3b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool3'))\n",
    "        # 4th layer group\n",
    "        model.add(Conv3D(128, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv4a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(128, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv4b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool4'))\n",
    "\n",
    "        # 5th layer group\n",
    "        model.add(Conv3D(256, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv5a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(256, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv5b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='valid', name='pool5'))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # FC layers group\n",
    "        model.add(Dense(512, activation='relu', name='fc6'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512, activation='relu', name='fc7'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d3(cls, input_shape, nb_classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, kernel_size=(3, 3, 3), input_shape=input_shape, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(16, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    " \n",
    "    @classmethod\n",
    "    def c3d4(cls, input_shape, nb_classes):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv3D(8, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(16, kernel_size=(3,3,3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        #Flatten Layers\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #softmax layer\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d5(cls, input_shape, nb_classes):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv3D(8, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(16, kernel_size=(3,3,3), padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(1,3,3), padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        #Flatten Layers\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #softmax layer\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        return model   \n",
    "    \n",
    "    @classmethod\n",
    "    def lstm(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a simple LSTM network. We pass the extracted features from\n",
    "        our CNN to this model predomenently.\"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(2048, return_sequences=False,\n",
    "                       input_shape=input_shape,\n",
    "                       dropout=0.5))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def lrcn(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),\n",
    "            activation='relu', padding='same'), input_shape=input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "            kernel_initializer=\"he_normal\", activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def mlp(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a simple MLP. It uses extracted features as the input\n",
    "        because of the otherwise too-high dimensionality.\"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=input_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, num_epochs, model, train_generator, val_generator, optimiser=None):\n",
    "\n",
    "    curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "    num_train_sequences = len(train_doc)\n",
    "    print('# training sequences =', num_train_sequences)\n",
    "    num_val_sequences = len(val_doc)\n",
    "    print('# validation sequences =', num_val_sequences)\n",
    "    print('# batch size =', batch_size)    \n",
    "    print('# epochs =', num_epochs)\n",
    "\n",
    "    #optimizer = Adam(lr=rate) \n",
    "    #write your optimizer\n",
    "    if optimiser == None:\n",
    "        optimiser = Adam() \n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print (model.summary())\n",
    "    \n",
    "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "            \n",
    "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only=True, \n",
    "                                 mode='auto', \n",
    "                                 period=1)\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                callbacks=callbacks_list, validation_data=val_generator, \n",
    "                validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 1 </font> :<font color = blue> Resize to 120*120,  `Raw image input`, `No cropping`, `No normalisation`, `No agumentation`, `No flipped images`, `No edge detection` </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/envs/cuda101/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 74.9751 - categorical_accuracy: 0.2220Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 114s 3s/step - loss: 73.6653 - categorical_accuracy: 0.2223 - val_loss: 1.6096 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60960, saving model to model_init_2021-11-1515_30_45.353161/model-00001-29.13229-0.23228-1.60960-0.16000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 16s 467ms/step - loss: 1.6234 - categorical_accuracy: 0.1916 - val_loss: 1.5651 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60960 to 1.56513, saving model to model_init_2021-11-1515_30_45.353161/model-00002-1.61635-0.23529-1.56513-0.29000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 14s 433ms/step - loss: 1.5785 - categorical_accuracy: 0.3326 - val_loss: 1.5509 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.56513 to 1.55091, saving model to model_init_2021-11-1515_30_45.353161/model-00003-1.59481-0.30392-1.55091-0.24000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 15s 461ms/step - loss: 1.5191 - categorical_accuracy: 0.2010 - val_loss: 1.3123 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.55091 to 1.31225, saving model to model_init_2021-11-1515_30_45.353161/model-00004-1.48645-0.23529-1.31225-0.34000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 16s 468ms/step - loss: 1.6541 - categorical_accuracy: 0.2467 - val_loss: 1.5957 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.31225\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 15s 456ms/step - loss: 1.5749 - categorical_accuracy: 0.2054 - val_loss: 1.4068 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.31225\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 15s 446ms/step - loss: 1.4973 - categorical_accuracy: 0.2958 - val_loss: 1.2222 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.31225 to 1.22219, saving model to model_init_2021-11-1515_30_45.353161/model-00007-1.47309-0.28431-1.22219-0.47000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 16s 479ms/step - loss: 1.4417 - categorical_accuracy: 0.4100 - val_loss: 1.2776 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.22219\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 16s 478ms/step - loss: 1.3355 - categorical_accuracy: 0.3377 - val_loss: 1.1865 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.22219 to 1.18652, saving model to model_init_2021-11-1515_30_45.353161/model-00009-1.26032-0.41176-1.18652-0.42000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 15s 441ms/step - loss: 1.0742 - categorical_accuracy: 0.5982 - val_loss: 1.1189 - val_categorical_accuracy: 0.4700\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.18652 to 1.11887, saving model to model_init_2021-11-1515_30_45.353161/model-00010-1.05300-0.58824-1.11887-0.47000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 15s 467ms/step - loss: 1.2532 - categorical_accuracy: 0.4159 - val_loss: 1.1150 - val_categorical_accuracy: 0.5800\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.11887 to 1.11504, saving model to model_init_2021-11-1515_30_45.353161/model-00011-1.17767-0.47059-1.11504-0.58000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 15s 463ms/step - loss: 1.1428 - categorical_accuracy: 0.5385 - val_loss: 1.2664 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.11504\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 15s 464ms/step - loss: 0.9021 - categorical_accuracy: 0.7270 - val_loss: 0.9758 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.11504 to 0.97581, saving model to model_init_2021-11-1515_30_45.353161/model-00013-0.98111-0.62745-0.97581-0.64000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 15s 449ms/step - loss: 0.9014 - categorical_accuracy: 0.6747 - val_loss: 1.4000 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.97581\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 14s 431ms/step - loss: 0.7698 - categorical_accuracy: 0.6568 - val_loss: 1.0510 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.97581\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 0.8394 - categorical_accuracy: 0.5959 - val_loss: 0.9692 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.97581 to 0.96917, saving model to model_init_2021-11-1515_30_45.353161/model-00016-0.73691-0.63725-0.96917-0.61000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 15s 466ms/step - loss: 0.8444 - categorical_accuracy: 0.6604 - val_loss: 0.9424 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.96917 to 0.94242, saving model to model_init_2021-11-1515_30_45.353161/model-00017-0.81036-0.71569-0.94242-0.62000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 16s 467ms/step - loss: 0.7761 - categorical_accuracy: 0.7295 - val_loss: 0.9572 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.94242\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 16s 468ms/step - loss: 0.6842 - categorical_accuracy: 0.7547 - val_loss: 0.7043 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.94242 to 0.70428, saving model to model_init_2021-11-1515_30_45.353161/model-00019-0.63748-0.74510-0.70428-0.72000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 16s 471ms/step - loss: 0.6943 - categorical_accuracy: 0.7941 - val_loss: 0.7568 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.70428\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 20\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <font color = red> Model 2 </font> :<font color = blue> Resize to 120*120, `agumentation`, `No flipped images`, `No cropping`, `No normalisation`, `No edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 63.3319 - categorical_accuracy: 0.2246Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 80s 2s/step - loss: 62.1864 - categorical_accuracy: 0.2248 - val_loss: 1.5842 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.58424, saving model to model_init_2021-11-1515_37_33.418258/model-00001-23.23821-0.23228-1.58424-0.36000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 17s 517ms/step - loss: 1.6020 - categorical_accuracy: 0.2623 - val_loss: 1.6154 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.58424\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 16s 471ms/step - loss: 1.6431 - categorical_accuracy: 0.3506 - val_loss: 1.5077 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.58424 to 1.50774, saving model to model_init_2021-11-1515_37_33.418258/model-00003-1.68435-0.29902-1.50774-0.34000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 17s 512ms/step - loss: 1.6058 - categorical_accuracy: 0.3004 - val_loss: 1.5245 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.50774\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 17s 509ms/step - loss: 1.5104 - categorical_accuracy: 0.3640 - val_loss: 1.3558 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50774 to 1.35576, saving model to model_init_2021-11-1515_37_33.418258/model-00005-1.51589-0.35784-1.35576-0.38000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 17s 513ms/step - loss: 1.5223 - categorical_accuracy: 0.3137 - val_loss: 1.3163 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.35576 to 1.31628, saving model to model_init_2021-11-1515_37_33.418258/model-00006-1.46955-0.34804-1.31628-0.44000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 17s 518ms/step - loss: 1.4226 - categorical_accuracy: 0.4571 - val_loss: 1.3775 - val_categorical_accuracy: 0.4800\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.31628\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 17s 498ms/step - loss: 1.4357 - categorical_accuracy: 0.3748 - val_loss: 1.1852 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.31628 to 1.18524, saving model to model_init_2021-11-1515_37_33.418258/model-00008-1.37393-0.42157-1.18524-0.54000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 18s 533ms/step - loss: 1.2449 - categorical_accuracy: 0.4929 - val_loss: 1.3796 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.18524\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 17s 515ms/step - loss: 1.3805 - categorical_accuracy: 0.4385 - val_loss: 1.3497 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.18524\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 17s 513ms/step - loss: 1.2820 - categorical_accuracy: 0.4061 - val_loss: 1.2320 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.18524\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 17s 506ms/step - loss: 1.3213 - categorical_accuracy: 0.5385 - val_loss: 1.1960 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.18524\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 16s 485ms/step - loss: 1.1658 - categorical_accuracy: 0.4833 - val_loss: 1.1565 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.18524 to 1.15655, saving model to model_init_2021-11-1515_37_33.418258/model-00013-1.10066-0.53431-1.15655-0.55000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 17s 515ms/step - loss: 1.2376 - categorical_accuracy: 0.4443 - val_loss: 1.2348 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.15655\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 17s 495ms/step - loss: 1.0089 - categorical_accuracy: 0.5996 - val_loss: 0.9939 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.15655 to 0.99389, saving model to model_init_2021-11-1515_37_33.418258/model-00015-0.98938-0.60294-0.99389-0.61000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 1.0440 - categorical_accuracy: 0.5739 - val_loss: 1.0957 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.99389\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 17s 500ms/step - loss: 1.0176 - categorical_accuracy: 0.5718 - val_loss: 0.9897 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.99389 to 0.98966, saving model to model_init_2021-11-1515_37_33.418258/model-00017-1.01623-0.54412-0.98966-0.59000.h5\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 17s 516ms/step - loss: 1.0548 - categorical_accuracy: 0.5195 - val_loss: 0.9535 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.98966 to 0.95348, saving model to model_init_2021-11-1515_37_33.418258/model-00018-1.02859-0.51961-0.95348-0.63000.h5\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 16s 492ms/step - loss: 0.9035 - categorical_accuracy: 0.5979 - val_loss: 0.8999 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.95348 to 0.89991, saving model to model_init_2021-11-1515_37_33.418258/model-00019-0.93747-0.62255-0.89991-0.63000.h5\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 17s 516ms/step - loss: 0.8475 - categorical_accuracy: 0.6564 - val_loss: 1.0181 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.89991\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 3 </font> :<font color = blue> Resize to 120*120, `agumentation`, `flipped images`, `No normalisation`, `No cropping`, `No edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 111.8539 - categorical_accuracy: 0.1896Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 99s 3s/step - loss: 109.8378 - categorical_accuracy: 0.1901 - val_loss: 1.5109 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.51089, saving model to model_init_2021-11-1515_44_17.698701/model-00001-41.28883-0.20764-1.51089-0.37000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 21s 631ms/step - loss: 1.5272 - categorical_accuracy: 0.2733 - val_loss: 1.5235 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.51089\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 20s 613ms/step - loss: 1.5376 - categorical_accuracy: 0.3104 - val_loss: 1.5166 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.51089\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 20s 602ms/step - loss: 1.5673 - categorical_accuracy: 0.2218 - val_loss: 1.3226 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.51089 to 1.32258, saving model to model_init_2021-11-1515_44_17.698701/model-00004-1.52372-0.28105-1.32258-0.45000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 21s 630ms/step - loss: 1.3647 - categorical_accuracy: 0.3310 - val_loss: 1.2097 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.32258 to 1.20965, saving model to model_init_2021-11-1515_44_17.698701/model-00005-1.37267-0.36928-1.20965-0.49000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 21s 621ms/step - loss: 1.3390 - categorical_accuracy: 0.4758 - val_loss: 1.1727 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.20965 to 1.17269, saving model to model_init_2021-11-1515_44_17.698701/model-00006-1.31691-0.44444-1.17269-0.44000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 21s 616ms/step - loss: 1.2683 - categorical_accuracy: 0.3968 - val_loss: 1.0469 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.17269 to 1.04688, saving model to model_init_2021-11-1515_44_17.698701/model-00007-1.22226-0.45425-1.04688-0.55000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 20s 612ms/step - loss: 1.2397 - categorical_accuracy: 0.4984 - val_loss: 1.0784 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.04688\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 21s 627ms/step - loss: 0.7826 - categorical_accuracy: 0.6786 - val_loss: 0.9338 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.04688 to 0.93376, saving model to model_init_2021-11-1515_44_17.698701/model-00009-0.91564-0.63072-0.93376-0.62000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 20s 605ms/step - loss: 0.8674 - categorical_accuracy: 0.6606 - val_loss: 0.9602 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.93376\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 20s 616ms/step - loss: 0.8936 - categorical_accuracy: 0.6639 - val_loss: 0.8965 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.93376 to 0.89645, saving model to model_init_2021-11-1515_44_17.698701/model-00011-0.90888-0.63399-0.89645-0.65000.h5\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 20s 613ms/step - loss: 0.8920 - categorical_accuracy: 0.6094 - val_loss: 1.0329 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.89645\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 21s 617ms/step - loss: 1.0424 - categorical_accuracy: 0.6130 - val_loss: 0.8664 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.89645 to 0.86639, saving model to model_init_2021-11-1515_44_17.698701/model-00013-0.88425-0.63399-0.86639-0.60000.h5\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 20s 597ms/step - loss: 1.2980 - categorical_accuracy: 0.5713 - val_loss: 0.7528 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.86639 to 0.75279, saving model to model_init_2021-11-1515_44_17.698701/model-00014-1.00307-0.58170-0.75279-0.66000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 20s 610ms/step - loss: 0.5584 - categorical_accuracy: 0.7946 - val_loss: 0.7725 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.75279\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 20s 606ms/step - loss: 0.4654 - categorical_accuracy: 0.8242 - val_loss: 0.7634 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.75279\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 22s 656ms/step - loss: 0.5943 - categorical_accuracy: 0.7777 - val_loss: 0.7619 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.75279\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 20s 595ms/step - loss: 0.6664 - categorical_accuracy: 0.7676 - val_loss: 0.7758 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.75279\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 20s 607ms/step - loss: 0.7181 - categorical_accuracy: 0.7382 - val_loss: 0.7655 - val_categorical_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss did not improve from 0.75279\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 21s 621ms/step - loss: 0.5433 - categorical_accuracy: 0.7960 - val_loss: 0.6684 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.75279 to 0.66837, saving model to model_init_2021-11-1515_44_17.698701/model-00020-0.66264-0.74837-0.66837-0.75000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 4 </font> :<font color = blue> Resize to 120*120, `agumentation`, `flipped images`, `normalisation`, `No cropping`, `No edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.2261 - categorical_accuracy: 0.2205Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 88s 3s/step - loss: 3.1948 - categorical_accuracy: 0.2212 - val_loss: 212.7136 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 212.71359, saving model to model_init_2021-11-1515_52_29.639986/model-00001-2.13364-0.24334-212.71359-0.29000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 21s 636ms/step - loss: 1.5967 - categorical_accuracy: 0.2627 - val_loss: 1.5947 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: val_loss improved from 212.71359 to 1.59465, saving model to model_init_2021-11-1515_52_29.639986/model-00002-1.62387-0.19935-1.59465-0.24000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 21s 626ms/step - loss: 1.6000 - categorical_accuracy: 0.2790 - val_loss: 1.5858 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.59465 to 1.58577, saving model to model_init_2021-11-1515_52_29.639986/model-00003-1.60595-0.19608-1.58577-0.24000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 20s 611ms/step - loss: 1.6434 - categorical_accuracy: 0.1010 - val_loss: 1.6064 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58577\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 22s 661ms/step - loss: 1.5885 - categorical_accuracy: 0.2794 - val_loss: 1.6083 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58577\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 21s 619ms/step - loss: 1.6364 - categorical_accuracy: 0.2084 - val_loss: 1.5965 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.58577\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 22s 651ms/step - loss: 1.6117 - categorical_accuracy: 0.2197 - val_loss: 1.5951 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.58577\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 21s 631ms/step - loss: 1.6083 - categorical_accuracy: 0.2046 - val_loss: 1.5898 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.58577\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 21s 639ms/step - loss: 1.6127 - categorical_accuracy: 0.2027 - val_loss: 1.5935 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.58577\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 21s 632ms/step - loss: 1.5988 - categorical_accuracy: 0.2558 - val_loss: 1.5898 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.58577\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 21s 632ms/step - loss: 1.6061 - categorical_accuracy: 0.2226 - val_loss: 1.5927 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.58577\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 22s 672ms/step - loss: 1.6102 - categorical_accuracy: 0.1514 - val_loss: 1.5900 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.58577\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 21s 635ms/step - loss: 1.6190 - categorical_accuracy: 0.1977 - val_loss: 1.5858 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.58577 to 1.58575, saving model to model_init_2021-11-1515_52_29.639986/model-00013-1.61504-0.20588-1.58575-0.28000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 21s 623ms/step - loss: 1.6168 - categorical_accuracy: 0.2112 - val_loss: 1.6026 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.58575\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 21s 637ms/step - loss: 1.6034 - categorical_accuracy: 0.2403 - val_loss: 1.5914 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.58575\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 21s 634ms/step - loss: 1.6090 - categorical_accuracy: 0.2394 - val_loss: 1.5930 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.58575\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 21s 641ms/step - loss: 1.6141 - categorical_accuracy: 0.1790 - val_loss: 1.5893 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.58575\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 1.5970 - categorical_accuracy: 0.2697 - val_loss: 1.6040 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.58575\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 22s 655ms/step - loss: 1.5986 - categorical_accuracy: 0.2043 - val_loss: 1.5926 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.58575\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 21s 617ms/step - loss: 1.6163 - categorical_accuracy: 0.1512 - val_loss: 1.5976 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.58575\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 5 </font> :<font color = blue> Resize to 120*120, `agumentation`, `flipped images`, `normalisation`, `cropping`, `No edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.4559 - categorical_accuracy: 0.2038Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 90s 3s/step - loss: 2.4401 - categorical_accuracy: 0.2037 - val_loss: 7.6371 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.63714, saving model to model_init_2021-11-1516_00_43.650050/model-00001-1.90237-0.20161-7.63714-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 21s 627ms/step - loss: 1.6064 - categorical_accuracy: 0.1738 - val_loss: 7.4701 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.63714 to 7.47008, saving model to model_init_2021-11-1516_00_43.650050/model-00002-1.60947-0.18954-7.47008-0.29000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 21s 631ms/step - loss: 1.5969 - categorical_accuracy: 0.2217 - val_loss: 8.1010 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 7.47008\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 22s 645ms/step - loss: 1.6245 - categorical_accuracy: 0.1802 - val_loss: 7.5372 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.47008\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 1.6132 - categorical_accuracy: 0.1997 - val_loss: 7.7941 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 7.47008\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 21s 637ms/step - loss: 1.6247 - categorical_accuracy: 0.1507 - val_loss: 7.5853 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.47008\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 20s 604ms/step - loss: 1.6155 - categorical_accuracy: 0.1854 - val_loss: 7.4437 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.47008 to 7.44371, saving model to model_init_2021-11-1516_00_43.650050/model-00007-1.61713-0.14379-7.44371-0.19000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 21s 636ms/step - loss: 1.6053 - categorical_accuracy: 0.2094 - val_loss: 8.0436 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.44371\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 22s 670ms/step - loss: 1.6045 - categorical_accuracy: 0.2390 - val_loss: 7.3802 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.44371 to 7.38017, saving model to model_init_2021-11-1516_00_43.650050/model-00009-1.61024-0.21569-7.38017-0.19000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 21s 634ms/step - loss: 1.6051 - categorical_accuracy: 0.2259 - val_loss: 7.4420 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.38017\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 22s 669ms/step - loss: 1.6156 - categorical_accuracy: 0.1842 - val_loss: 7.6133 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.38017\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 21s 615ms/step - loss: 1.6133 - categorical_accuracy: 0.2089 - val_loss: 7.7277 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.38017\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 21s 637ms/step - loss: 1.6072 - categorical_accuracy: 0.2091 - val_loss: 7.6900 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 7.38017\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 21s 627ms/step - loss: 1.6227 - categorical_accuracy: 0.1270 - val_loss: 7.3112 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.38017 to 7.31122, saving model to model_init_2021-11-1516_00_43.650050/model-00014-1.61584-0.16340-7.31122-0.24000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 21s 636ms/step - loss: 1.6057 - categorical_accuracy: 0.2144 - val_loss: 7.3467 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.31122\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 1.6119 - categorical_accuracy: 0.1911 - val_loss: 7.5040 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.31122\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 21s 618ms/step - loss: 1.6140 - categorical_accuracy: 0.1710 - val_loss: 7.7352 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 7.31122\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 21s 642ms/step - loss: 1.6057 - categorical_accuracy: 0.2248 - val_loss: 8.2934 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 7.31122\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 21s 616ms/step - loss: 1.6096 - categorical_accuracy: 0.2185 - val_loss: 7.1638 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00019: val_loss improved from 7.31122 to 7.16376, saving model to model_init_2021-11-1516_00_43.650050/model-00019-1.61297-0.19935-7.16376-0.16000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 21s 636ms/step - loss: 1.6076 - categorical_accuracy: 0.1684 - val_loss: 7.7744 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 7.16376\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 6 </font> :<font color = blue> Resize to 120*120, `agumentation`, `flipped images`, `normalisation`, `cropping`, `edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.1843 - categorical_accuracy: 0.1997Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 97s 3s/step - loss: 2.1728 - categorical_accuracy: 0.2004 - val_loss: 488.3638 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 488.36380, saving model to model_init_2021-11-1516_08_58.728662/model-00001-1.78110-0.22474-488.36380-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 22s 663ms/step - loss: 1.6371 - categorical_accuracy: 0.2016 - val_loss: 27.4141 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00002: val_loss improved from 488.36380 to 27.41413, saving model to model_init_2021-11-1516_08_58.728662/model-00002-1.63098-0.20588-27.41413-0.15000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 21s 640ms/step - loss: 1.6285 - categorical_accuracy: 0.1004 - val_loss: 26.0180 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00003: val_loss improved from 27.41413 to 26.01803, saving model to model_init_2021-11-1516_08_58.728662/model-00003-1.63081-0.12092-26.01803-0.23000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 1.6086 - categorical_accuracy: 0.2366 - val_loss: 25.5409 - val_categorical_accuracy: 0.1300\n",
      "\n",
      "Epoch 00004: val_loss improved from 26.01803 to 25.54092, saving model to model_init_2021-11-1516_08_58.728662/model-00004-1.61416-0.21242-25.54092-0.13000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 22s 676ms/step - loss: 1.6177 - categorical_accuracy: 0.1527 - val_loss: 24.2375 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: val_loss improved from 25.54092 to 24.23753, saving model to model_init_2021-11-1516_08_58.728662/model-00005-1.61405-0.16993-24.23753-0.18000.h5\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 22s 671ms/step - loss: 1.6204 - categorical_accuracy: 0.1882 - val_loss: 23.0150 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00006: val_loss improved from 24.23753 to 23.01501, saving model to model_init_2021-11-1516_08_58.728662/model-00006-1.62024-0.17320-23.01501-0.18000.h5\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 23s 683ms/step - loss: 1.6013 - categorical_accuracy: 0.2941 - val_loss: 22.1988 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00007: val_loss improved from 23.01501 to 22.19881, saving model to model_init_2021-11-1516_08_58.728662/model-00007-1.61120-0.25163-22.19881-0.19000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 22s 662ms/step - loss: 1.6224 - categorical_accuracy: 0.2089 - val_loss: 23.8312 - val_categorical_accuracy: 0.1900\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 22.19881\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 22s 660ms/step - loss: 1.6228 - categorical_accuracy: 0.2036 - val_loss: 21.2565 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss improved from 22.19881 to 21.25649, saving model to model_init_2021-11-1516_08_58.728662/model-00009-1.62116-0.17647-21.25649-0.20000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 22s 653ms/step - loss: 1.6128 - categorical_accuracy: 0.2205 - val_loss: 23.1897 - val_categorical_accuracy: 0.1700\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 21.25649\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 23s 677ms/step - loss: 1.6205 - categorical_accuracy: 0.1816 - val_loss: 21.2625 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 21.25649\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 21s 631ms/step - loss: 1.6281 - categorical_accuracy: 0.1805 - val_loss: 20.3695 - val_categorical_accuracy: 0.2200\n",
      "\n",
      "Epoch 00012: val_loss improved from 21.25649 to 20.36946, saving model to model_init_2021-11-1516_08_58.728662/model-00012-1.61301-0.20261-20.36946-0.22000.h5\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 23s 681ms/step - loss: 1.6125 - categorical_accuracy: 0.1655 - val_loss: 21.8047 - val_categorical_accuracy: 0.1400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 20.36946\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 22s 673ms/step - loss: 1.6122 - categorical_accuracy: 0.2197 - val_loss: 20.1661 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00014: val_loss improved from 20.36946 to 20.16608, saving model to model_init_2021-11-1516_08_58.728662/model-00014-1.61638-0.22222-20.16608-0.18000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 22s 667ms/step - loss: 1.6096 - categorical_accuracy: 0.2346 - val_loss: 20.6810 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 20.16608\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 22s 661ms/step - loss: 1.6161 - categorical_accuracy: 0.1853 - val_loss: 19.4055 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00016: val_loss improved from 20.16608 to 19.40549, saving model to model_init_2021-11-1516_08_58.728662/model-00016-1.60879-0.21895-19.40549-0.18000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 22s 660ms/step - loss: 1.6172 - categorical_accuracy: 0.2004 - val_loss: 19.5810 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 19.40549\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 23s 680ms/step - loss: 1.6124 - categorical_accuracy: 0.1870 - val_loss: 19.9206 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 19.40549\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 22s 667ms/step - loss: 1.6102 - categorical_accuracy: 0.2355 - val_loss: 20.4402 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 19.40549\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 22s 663ms/step - loss: 1.6087 - categorical_accuracy: 0.2060 - val_loss: 21.4176 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 19.40549\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <font color = red> Model 7 </font> :<font color = blue> Resize to 120*120, `All except normalization`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 863,877\n",
      "Trainable params: 863,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 49.8937 - categorical_accuracy: 0.2228Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 95s 3s/step - loss: 49.0049 - categorical_accuracy: 0.2225 - val_loss: 1.6112 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61125, saving model to model_init_2021-11-1516_19_28.358405/model-00001-18.78768-0.21116-1.61125-0.16000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 21s 622ms/step - loss: 1.5968 - categorical_accuracy: 0.2467 - val_loss: 1.6024 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61125 to 1.60240, saving model to model_init_2021-11-1516_19_28.358405/model-00002-1.61881-0.22549-1.60240-0.26000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 20s 598ms/step - loss: 1.6262 - categorical_accuracy: 0.1768 - val_loss: 1.6011 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60240 to 1.60106, saving model to model_init_2021-11-1516_19_28.358405/model-00003-1.62486-0.19608-1.60106-0.27000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 21s 624ms/step - loss: 1.5987 - categorical_accuracy: 0.2290 - val_loss: 1.5444 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.60106 to 1.54441, saving model to model_init_2021-11-1516_19_28.358405/model-00004-1.60819-0.21895-1.54441-0.43000.h5\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 21s 635ms/step - loss: 1.5630 - categorical_accuracy: 0.2591 - val_loss: 1.5655 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.54441\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 20s 615ms/step - loss: 1.5865 - categorical_accuracy: 0.2698 - val_loss: 1.5521 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.54441\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 20s 610ms/step - loss: 1.5903 - categorical_accuracy: 0.2418 - val_loss: 1.5357 - val_categorical_accuracy: 0.3600\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.54441 to 1.53568, saving model to model_init_2021-11-1516_19_28.358405/model-00007-1.59262-0.25817-1.53568-0.36000.h5\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 22s 667ms/step - loss: 1.5959 - categorical_accuracy: 0.2147 - val_loss: 1.5309 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.53568 to 1.53090, saving model to model_init_2021-11-1516_19_28.358405/model-00008-1.61260-0.23529-1.53090-0.27000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 22s 650ms/step - loss: 1.5549 - categorical_accuracy: 0.2847 - val_loss: 1.5776 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.53090\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 20s 607ms/step - loss: 1.5759 - categorical_accuracy: 0.2841 - val_loss: 1.5098 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.53090 to 1.50981, saving model to model_init_2021-11-1516_19_28.358405/model-00010-1.55152-0.27778-1.50981-0.34000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 21s 622ms/step - loss: 1.5142 - categorical_accuracy: 0.3547 - val_loss: 1.5160 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.50981\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 21s 623ms/step - loss: 1.5337 - categorical_accuracy: 0.2886 - val_loss: 1.5527 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.50981\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 21s 623ms/step - loss: 1.5712 - categorical_accuracy: 0.2805 - val_loss: 1.5302 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.50981\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 19s 584ms/step - loss: 1.5031 - categorical_accuracy: 0.3605 - val_loss: 1.5061 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.50981 to 1.50611, saving model to model_init_2021-11-1516_19_28.358405/model-00014-1.47450-0.36275-1.50611-0.37000.h5\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 21s 630ms/step - loss: 1.5464 - categorical_accuracy: 0.2692 - val_loss: 1.4893 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.50611 to 1.48926, saving model to model_init_2021-11-1516_19_28.358405/model-00015-1.52907-0.30065-1.48926-0.40000.h5\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 21s 629ms/step - loss: 1.5410 - categorical_accuracy: 0.3026 - val_loss: 1.4700 - val_categorical_accuracy: 0.4100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 1.48926 to 1.47001, saving model to model_init_2021-11-1516_19_28.358405/model-00016-1.50791-0.30065-1.47001-0.41000.h5\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 21s 632ms/step - loss: 1.5718 - categorical_accuracy: 0.2994 - val_loss: 1.4912 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.47001\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 21s 623ms/step - loss: 1.5142 - categorical_accuracy: 0.3157 - val_loss: 1.5342 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.47001\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 20s 615ms/step - loss: 1.4405 - categorical_accuracy: 0.3289 - val_loss: 1.4700 - val_categorical_accuracy: 0.4400\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.47001 to 1.47000, saving model to model_init_2021-11-1516_19_28.358405/model-00019-1.45983-0.31699-1.47000-0.44000.h5\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 21s 626ms/step - loss: 1.5075 - categorical_accuracy: 0.3481 - val_loss: 1.4802 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.47000\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=False, crop=True, edge=False)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 8 </font> :<font color = blue> Resize to 120*120, `No agumentation,No flipped images,No normalisation,No cropping,No edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.2819 - categorical_accuracy: 0.2732Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 67s 2s/step - loss: 2.2758 - categorical_accuracy: 0.2741 - val_loss: 10.5653 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.56533, saving model to model_init_2021-11-1516_31_12.042035/model-00001-2.06603-0.30468-10.56533-0.25000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 15s 457ms/step - loss: 1.7343 - categorical_accuracy: 0.4673 - val_loss: 22.0977 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 10.56533\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 15s 461ms/step - loss: 1.8589 - categorical_accuracy: 0.2565 - val_loss: 3.9756 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00003: val_loss improved from 10.56533 to 3.97558, saving model to model_init_2021-11-1516_31_12.042035/model-00003-1.94266-0.25490-3.97558-0.28000.h5\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 16s 468ms/step - loss: 2.0501 - categorical_accuracy: 0.2941 - val_loss: 4.9660 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.97558\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 16s 495ms/step - loss: 2.1791 - categorical_accuracy: 0.3093 - val_loss: 16.1955 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.97558\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 15s 461ms/step - loss: 2.1381 - categorical_accuracy: 0.2389 - val_loss: 6.5411 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.97558\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 14s 423ms/step - loss: 2.1876 - categorical_accuracy: 0.2371 - val_loss: 4.2888 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.97558\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 16s 485ms/step - loss: 1.9007 - categorical_accuracy: 0.3036 - val_loss: 2.7980 - val_categorical_accuracy: 0.1600\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.97558 to 2.79800, saving model to model_init_2021-11-1516_31_12.042035/model-00008-1.97606-0.27451-2.79800-0.16000.h5\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 16s 484ms/step - loss: 1.7512 - categorical_accuracy: 0.3752 - val_loss: 1.6809 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.79800 to 1.68088, saving model to model_init_2021-11-1516_31_12.042035/model-00009-1.81113-0.32353-1.68088-0.38000.h5\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 15s 451ms/step - loss: 2.0303 - categorical_accuracy: 0.2165 - val_loss: 1.6006 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.68088 to 1.60063, saving model to model_init_2021-11-1516_31_12.042035/model-00010-2.01926-0.25490-1.60063-0.29000.h5\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 15s 462ms/step - loss: 2.0202 - categorical_accuracy: 0.2666 - val_loss: 2.0545 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.60063\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 15s 465ms/step - loss: 1.7591 - categorical_accuracy: 0.3170 - val_loss: 2.3913 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.60063\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 15s 454ms/step - loss: 1.9615 - categorical_accuracy: 0.2949 - val_loss: 2.4481 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.60063\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 16s 487ms/step - loss: 1.5803 - categorical_accuracy: 0.2824 - val_loss: 2.3310 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.60063\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 15s 443ms/step - loss: 1.6258 - categorical_accuracy: 0.3357 - val_loss: 2.4156 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.60063\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 15s 444ms/step - loss: 2.0335 - categorical_accuracy: 0.2763 - val_loss: 2.1948 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.60063\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 16s 472ms/step - loss: 1.6722 - categorical_accuracy: 0.4019 - val_loss: 1.9808 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.60063\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 16s 467ms/step - loss: 1.8805 - categorical_accuracy: 0.3454 - val_loss: 2.1531 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.60063\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 16s 482ms/step - loss: 1.7570 - categorical_accuracy: 0.3825 - val_loss: 1.8274 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.60063\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 16s 467ms/step - loss: 1.9354 - categorical_accuracy: 0.2920 - val_loss: 1.7598 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.60063\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator()\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = red> Model 9 </font> :<font color = blue> Resize to 120*120, `agumentation, flipped images, normalisation, cropping, edge detection`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 20\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 20, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 2, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.5114 - categorical_accuracy: 0.2150Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 96s 3s/step - loss: 2.4942 - categorical_accuracy: 0.2159 - val_loss: 43.5951 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 43.59515, saving model to model_init_2021-11-1517_21_22.062260/model-00001-1.90782-0.24585-43.59515-0.23000.h5\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 22s 653ms/step - loss: 1.6175 - categorical_accuracy: 0.2632 - val_loss: 34.8779 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: val_loss improved from 43.59515 to 34.87786, saving model to model_init_2021-11-1517_21_22.062260/model-00002-1.61034-0.24510-34.87786-0.24000.h5\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 23s 696ms/step - loss: 1.5587 - categorical_accuracy: 0.3045 - val_loss: 67.7408 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 34.87786\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 22s 669ms/step - loss: 1.5470 - categorical_accuracy: 0.3527 - val_loss: 104.8260 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 22s 648ms/step - loss: 1.4448 - categorical_accuracy: 0.3869 - val_loss: 116.6343 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 34.87786\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 23s 684ms/step - loss: 1.5405 - categorical_accuracy: 0.3291 - val_loss: 68.1942 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 21s 638ms/step - loss: 1.5679 - categorical_accuracy: 0.3044 - val_loss: 133.9462 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 34.87786\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 22s 655ms/step - loss: 1.4749 - categorical_accuracy: 0.3722 - val_loss: 174.3808 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 22s 654ms/step - loss: 1.4381 - categorical_accuracy: 0.3811 - val_loss: 261.5226 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 34.87786\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 21s 631ms/step - loss: 1.4564 - categorical_accuracy: 0.3813 - val_loss: 304.6552 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 21s 633ms/step - loss: 1.4380 - categorical_accuracy: 0.3560 - val_loss: 300.9625 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 34.87786\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 22s 671ms/step - loss: 1.4150 - categorical_accuracy: 0.4000 - val_loss: 381.8467 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 21s 634ms/step - loss: 1.4917 - categorical_accuracy: 0.3855 - val_loss: 357.1022 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 34.87786\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 22s 655ms/step - loss: 1.4594 - categorical_accuracy: 0.3759 - val_loss: 486.1489 - val_categorical_accuracy: 0.2900\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 21s 633ms/step - loss: 1.3397 - categorical_accuracy: 0.4845 - val_loss: 538.6412 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 34.87786\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 22s 649ms/step - loss: 1.5043 - categorical_accuracy: 0.4039 - val_loss: 605.9830 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 22s 656ms/step - loss: 1.4898 - categorical_accuracy: 0.3093 - val_loss: 734.7726 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 34.87786\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 22s 660ms/step - loss: 1.4277 - categorical_accuracy: 0.4343 - val_loss: 587.3335 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 22s 657ms/step - loss: 1.4008 - categorical_accuracy: 0.4078 - val_loss: 783.2123 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 34.87786\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 21s 638ms/step - loss: 1.4964 - categorical_accuracy: 0.3728 - val_loss: 775.3421 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 34.87786\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (20,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue> Observation: <font> \n",
    "`Model 3` is having training and validation accuracy as `79.6%` and `75.0%` which shows model is Good model and able to learn the behaviour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = green> Conclusion:<font> \n",
    "\n",
    "After all above model experiment, we are going to choose `Model 3` - <font color = blue> Resize to 120*120, `agumentation`, `flipped images`, `No normalisation`, `No cropping`, `No edge detection`</font> as good model which performed well.\n",
    "\n",
    "`Epoch 00020: val_loss improved from 0.75279 to 0.66837, saving model to model_init_2021-11-1515_44_17.698701/model-00020-0.66264-0.74837-0.66837-0.75000.h5`\n",
    "\n",
    "Number of Epoch = 20         \n",
    "Batch Size = 20         \n",
    "Number of parameters =  16,612,069\n",
    "\n",
    "Best Model file: `model-00020-0.66264-0.74837-0.66837-0.75000.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\">========================================================================== </font>\n",
    "## <center> <font color=\"blue\">                       End of the case study , thank you                     </font> </center>\n",
    "## <font color=\"green\">========================================================================== </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
